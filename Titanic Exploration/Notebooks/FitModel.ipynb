{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Pipeline: Fit a basic model\n",
    "\n",
    "Using the Titanic dataset from [this](https://www.kaggle.com/c/titanic/overview) Kaggle competition.\n",
    "\n",
    "In this section, we will fit and evaluate a basic model using 5-fold Cross-Validation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read in data\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import pandas as pd\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\r\n",
    "\r\n",
    "tr_features = pd.read_csv('../train_features.csv')\r\n",
    "tr_labels = pd.read_csv('../train_labels.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fit and evaluate a basic model using 5-fold Cross-Validation\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "rf = RandomForestClassifier()\r\n",
    "\r\n",
    "#.values.ravel() corrects warning for array; replaces column-vector\r\n",
    "scores = cross_val_score(rf, tr_features, tr_labels.values.ravel(), cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "scores"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.82242991, 0.8411215 , 0.79439252, 0.79439252, 0.83018868])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now have our cross-validated scores of our Random Forest classifier model, we used a cross-validate value of 5, which basically means we ran our model on 5 subsets of our training data. Now that we have five samples, we could very well find the mean for the five and call it a day, but with a range from 79-85% a lot of things could go wrong given strict limits. To fine tune our model before moving forward with an average value, we can try to tune our models hyperparameters. \r\n",
    "\r\n",
    "### Tune Hyperparameters\r\n",
    "\r\n",
    "**Parameters** - Fare = $20, Ticket Class = 3rd\r\n",
    "\r\n",
    "**Hyperparameters** - max depth of tree, features to consider, etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#function to print results of our model and hyperparameter adjustments\r\n",
    "def print_results(results):\r\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\r\n",
    "\r\n",
    "    means = results.cv_results_['mean_test_score']\r\n",
    "    stds = results.cv_results_['std_test_score']\r\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\r\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#assign variable for randomforestclassifier which is a series of decision trees\r\n",
    "rf = RandomForestClassifier()\r\n",
    "#create dict of parameters to build models\r\n",
    "#n_estimators = how many trees or decisions to build within our random forest\r\n",
    "#max_depth = how deep each of the individual trees go\r\n",
    "parameters = {\r\n",
    "    'n_estimators': [5, 50, 100],\r\n",
    "    'max_depth': [2, 10, 20, None]\r\n",
    "}\r\n",
    "\r\n",
    "#gridsearchcv stored into an object/variable\r\n",
    "cv = GridSearchCV(rf, parameters, cv=5)\r\n",
    "#call stored object and fit with training dataset\r\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\r\n",
    "\r\n",
    "#use the print function to display the results of the GridSearchModels created\r\n",
    "print_results(cv)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BEST PARAMS: {'max_depth': 10, 'n_estimators': 50}\n",
      "\n",
      "0.779 (+/-0.093) for {'max_depth': 2, 'n_estimators': 5}\n",
      "0.792 (+/-0.131) for {'max_depth': 2, 'n_estimators': 50}\n",
      "0.794 (+/-0.11) for {'max_depth': 2, 'n_estimators': 100}\n",
      "0.811 (+/-0.058) for {'max_depth': 10, 'n_estimators': 5}\n",
      "0.822 (+/-0.056) for {'max_depth': 10, 'n_estimators': 50}\n",
      "0.811 (+/-0.055) for {'max_depth': 10, 'n_estimators': 100}\n",
      "0.785 (+/-0.056) for {'max_depth': 20, 'n_estimators': 5}\n",
      "0.813 (+/-0.026) for {'max_depth': 20, 'n_estimators': 50}\n",
      "0.807 (+/-0.019) for {'max_depth': 20, 'n_estimators': 100}\n",
      "0.787 (+/-0.061) for {'max_depth': None, 'n_estimators': 5}\n",
      "0.809 (+/-0.025) for {'max_depth': None, 'n_estimators': 50}\n",
      "0.815 (+/-0.029) for {'max_depth': None, 'n_estimators': 100}\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "493c74afe5c3389c18b31c611ca8d9adabe5d170bcbd9dca85ad5c9ec7b23f0e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}